# find strings in the JSON
text <- paste(text %||% read(file), collapse = "\n")
pattern <- '["](?:(?:\\\\.)|(?:[^"\\\\]))*?["]'
locs <- gregexpr(pattern, text, perl = TRUE)[[1]]
# if any are found, replace them with placeholders
replaced <- text
strings <- character()
replacements <- character()
if (!identical(c(locs), -1L)) {
# get the string values
starts <- locs
ends <- locs + attr(locs, "match.length") - 1L
strings <- substring(text, starts, ends)
# only keep those requiring escaping
strings <- grep("[[\\]{}:]", strings, perl = TRUE, value = TRUE)
# compute replacements
replacements <- sprintf('"\032%i\032"', seq_along(strings))
# replace the strings
mapply(function(string, replacement) {
replaced <<- sub(string, replacement, replaced, fixed = TRUE)
}, strings, replacements)
}
# transform the JSON into something the R parser understands
transformed <- replaced
transformed <- gsub("{}", "`names<-`(list(), character())", transformed, fixed = TRUE)
transformed <- gsub("[[{]", "list(", transformed, perl = TRUE)
transformed <- gsub("[]}]", ")", transformed, perl = TRUE)
transformed <- gsub(":", "=", transformed, fixed = TRUE)
text <- paste(transformed, collapse = "\n")
# parse it
json <- parse(text = text, keep.source = FALSE, srcfile = NULL)[[1L]]
# construct map between source strings, replaced strings
map <- as.character(parse(text = strings))
names(map) <- as.character(parse(text = replacements))
# convert to list
map <- as.list(map)
# remap strings in object
remapped <- renv_json_remap(json, map)
# evaluate
eval(remapped, envir = baseenv())
}
renv_json_remap <- function(json, map) {
# fix names
if (!is.null(names(json))) {
lhs <- match(names(json), names(map), nomatch = 0L)
rhs <- match(names(map), names(json), nomatch = 0L)
names(json)[rhs] <- map[lhs]
}
# fix values
if (is.character(json))
return(map[[json]] %||% json)
# handle true, false, null
if (is.name(json)) {
text <- as.character(json)
if (text == "true")
return(TRUE)
else if (text == "false")
return(FALSE)
else if (text == "null")
return(NULL)
}
# recurse
if (is.recursive(json)) {
for (i in seq_along(json)) {
json[i] <- list(renv_json_remap(json[[i]], map))
}
}
json
}
# load the renv profile, if any
renv_bootstrap_profile_load(project)
# construct path to library root
root <- renv_bootstrap_library_root(project)
# construct library prefix for platform
prefix <- renv_bootstrap_platform_prefix()
# construct full libpath
libpath <- file.path(root, prefix)
# attempt to load
if (renv_bootstrap_load(project, libpath, version))
return(TRUE)
# load failed; inform user we're about to bootstrap
prefix <- paste("# Bootstrapping renv", version)
postfix <- paste(rep.int("-", 77L - nchar(prefix)), collapse = "")
header <- paste(prefix, postfix)
message(header)
# perform bootstrap
bootstrap(version, libpath)
# exit early if we're just testing bootstrap
if (!is.na(Sys.getenv("RENV_BOOTSTRAP_INSTALL_ONLY", unset = NA)))
return(TRUE)
# try again to load
if (requireNamespace("renv", lib.loc = libpath, quietly = TRUE)) {
message("* Successfully installed and loaded renv ", version, ".")
return(renv::load())
}
# failed to download or load renv; warn the user
msg <- c(
"Failed to find an renv installation: the project will not be loaded.",
"Use `renv::activate()` to re-initialize the project."
)
warning(paste(msg, collapse = "\n"), call. = FALSE)
})
knitr::opts_chunk$set(echo = TRUE)
#### Load necessary packages ####
# * These packages are not necessary to complete the assignment and or only used
#   to provide an example.
packages <- c("knitr", "kableExtra", "magrittr", "readr", "geosphere")
install_me <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(install_me)) install.packages(install_me)
library(knitr)
library(kableExtra)
library(magrittr)
library(readr)
library(geosphere)
library(dplyr)
confirmed_df<-read.csv("data/time_series_covid19_confirmed_global.csv",
header=TRUE, stringsAsFactors=FALSE)
deaths_df<-read.csv("data/time_series_covid19_deaths_global.csv",
header=TRUE, stringsAsFactors=FALSE)
recovered_df<-read.csv("data/time_series_covid19_recovered_global.csv",
header=TRUE, stringsAsFactors=FALSE)
## Confirmed Dataset
confirmed_ordered<-select(arrange(confirmed_df, -X1.22.20),
Province.State, Country.Region, X1.22.20)
cat("Confirmed Dataset ")
head(confirmed_ordered)
## Deaths Dataset
death_ordered<-select(arrange(deaths_df, -X1.22.20),
Province.State, Country.Region, X1.22.20)
cat("Deaths Dataset ")
head(death_ordered)
## Recovered Dataset
recovered_ordered<-select(arrange(recovered_df, -X1.22.20),
Province.State, Country.Region, X1.22.20)
cat("Recovered Dataset \n")
head(recovered_ordered)
cat(confirmed_ordered[1,1], ", ", confirmed_ordered[1,2],
" has the most confirmed cases on the first day. \n",
death_ordered[1,1], ", ", death_ordered[1,2],
" has the most deaths from the virus on the first day. \n",
recovered_ordered[1,1], ", ", recovered_ordered[1,2],
" has the most recovered cases from the virus on the first day. \n",
sep="")
if (confirmed_ordered[1,1] == death_ordered[1,1] &&
confirmed_ordered[1,1] == recovered_ordered[1,1] &&
death_ordered[1,1] == recovered_ordered[1,1])
{
cat(confirmed_ordered[1,1], ", ", confirmed_ordered[1,2],
" is the most likely origin of the virus. \n", sep="")
}
confirmed_df<-read.csv("data/time_series_covid19_confirmed_global.csv",
header=TRUE, stringsAsFactors=FALSE)
recent_df<-arrange(confirmed_df[confirmed_df[,ncol(confirmed_df)-1] == 0
& confirmed_df[,ncol(confirmed_df)] > 0,])
i<-0
# If there are no new cases today loop back to find most recent region
# to have new cases
if (nrow(recent_df) == 0) {
while (nrow(recent_df) == 0) {
i<-i+1
recent_df<-arrange(confirmed_df[confirmed_df[,ncol(confirmed_df)-1-i] == 0
& confirmed_df[,ncol(confirmed_df)-i] > 0,])
}
}
head(select(recent_df, Province.State, Country.Region, ncol(confirmed_df)-1-i,
ncol(confirmed_df)-i))
# Vector is small enough that loop is reasonable
for(i in 1:nrow(recent_df))
{
if (recent_df[i,1] == "") {
cat(recent_df[i,2], "has recently had their first confirmed case. \n")
} else {
if (recent_df[i,2] == "") {
cat(recent_df[i,1], "has recently had their first confirmed case. \n")
} else {
cat(recent_df[i,1], ", ", recent_df[i,2],
" has recently had their first confirmed case. \n", sep="")
}
}
}
origin_df<-arrange(confirmed_df, -X1.22.20)[1,]
confirmed_df<-read.csv("data/time_series_covid19_confirmed_global.csv",
header=TRUE, stringsAsFactors=FALSE)
recent_df<-arrange(confirmed_df[confirmed_df[,ncol(confirmed_df)-1] == 0
& confirmed_df[,ncol(confirmed_df)] > 0,])
i<-0
# If there are no new cases today loop back to find most recent region
# to have new cases
if (nrow(recent_df) == 0) {
while (nrow(recent_df) == 0) {
i<-i+1
recent_df<-arrange(confirmed_df[confirmed_df[,ncol(confirmed_df)-1-i] == 0
& confirmed_df[,ncol(confirmed_df)-i] > 0,])
}
}
# Compute distances from origin
distances<-distm(select(recent_df, Long, Lat), select(origin_df, Long, Lat))
# Convert from m to miles
distances<-distances * 0.00062137
# Add distance from origin to dataframe and sort by distance
recent_df$distance<-distances[,1]
recent_df<-arrange(recent_df, distance)
head(select(recent_df, Province.State, Country.Region, Lat, Long, distance))
# Vector is small enough that loop is reasonable
for (i in 1:nrow(recent_df)) {
city<-recent_df[i, "Province.State"]
# If there is no city use country
if (city == "") {
city<-recent_df[i, "Country.Region"]
}
cat(city, "is", recent_df[i, "distance"],
"miles away from the virus origin in",
paste0(origin_df[1, "Province.State"], ","),
paste0(origin_df[1, "Country.Region"], "."), "\n")
}
# Datasets respresent a cumlative sum by date, so last column represents
# sumation for region
confirmed_df<-read.csv("data/time_series_covid19_confirmed_global.csv",
header=TRUE, stringsAsFactors=FALSE)
confirmed_df<-select(confirmed_df, Province.State,
Country.Region, ncol(confirmed_df))
names(confirmed_df)[3] <- "confirmed"
deaths_df<-read.csv("data/time_series_covid19_deaths_global.csv",
header=TRUE, stringsAsFactors=FALSE)
deaths_df<-select(deaths_df, Province.State,
Country.Region, ncol(deaths_df))
names(deaths_df)[3] <- "deaths"
recovered_df<-read.csv("data/time_series_covid19_recovered_global.csv",
header=TRUE, stringsAsFactors=FALSE)
recovered_df<-select(recovered_df, Province.State,
Country.Region, ncol(recovered_df))
names(recovered_df)[3] <- "recovered"
# Combine the datasets into one and fill NA with 0
combined_df<-full_join(confirmed_df, recovered_df,
by=c("Province.State", "Country.Region"))
combined_df<-full_join(combined_df, deaths_df,
by=c("Province.State", "Country.Region"))
combined_df[is.na(combined_df)] <- 0
# Assignment is unclear if we are to consider state and region or
# just region. Based on how data is formatted, I think it is cleaner
# and makes more sence to use region only.  For instance, in confirmed
# dataset, Canada is broken up by region, but in recovered dataset it
# uses Canada as a whole.  There are numerous examples of this in
# the data
grouped_df<-as.data.frame(summarise_each(group_by(
select(combined_df, -Province.State), Country.Region), sum))
# compute risk and burden by region
grouped_df$risk<-grouped_df$deaths / grouped_df$recovered
grouped_df$burden<-grouped_df$confirmed * grouped_df$risk
cat("Highest risk scores ")
head(arrange(grouped_df, -risk, -confirmed))
cat("Highest risk scores, that are not infinite ")
head(arrange(grouped_df[grouped_df$risk != Inf,], -risk, -confirmed))
cat("Lowest Risk Scores ")
head(arrange(grouped_df, risk, confirmed))
cat("Lowest risk scores, that are not zero ")
head(arrange(grouped_df[grouped_df$risk != 0,], risk, confirmed))
global_confirmed<-sum(grouped_df$confirmed)
global_deaths<-sum(grouped_df$deaths)
global_recovered<-sum(grouped_df$recovered)
global_risk<-global_deaths / global_recovered
global_burden<-global_confirmed * global_risk
cat("Global Data\n",
"Confirmed:", global_confirmed, "\n",
"Deaths:   ", global_deaths, "\n",
"Recovered:", global_recovered, "\n",
"Risk:     ", global_risk, "\n",
"Burden:   ", global_burden, "\n")
# Datasets respresent a cumlative sum by date, so last column represents
# sumation for region
confirmed_df<-read.csv("data/time_series_covid19_confirmed_global.csv",
header=TRUE, stringsAsFactors=FALSE)
confirmed_df<-select(confirmed_df, Province.State,
Country.Region, ncol(confirmed_df))
names(confirmed_df)[3] <- "confirmed"
deaths_df<-read.csv("data/time_series_covid19_deaths_global.csv",
header=TRUE, stringsAsFactors=FALSE)
deaths_df<-select(deaths_df, Province.State,
Country.Region, ncol(deaths_df))
names(deaths_df)[3] <- "deaths"
recovered_df<-read.csv("data/time_series_covid19_recovered_global.csv",
header=TRUE, stringsAsFactors=FALSE)
recovered_df<-select(recovered_df, Province.State,
Country.Region, ncol(recovered_df))
names(recovered_df)[3] <- "recovered"
# Combine the datasets into one and fill NA with 0
combined_df<-full_join(confirmed_df, recovered_df,
by=c("Province.State", "Country.Region"))
combined_df<-full_join(combined_df, deaths_df,
by=c("Province.State", "Country.Region"))
combined_df[is.na(combined_df)] <- 0
# Group and combine data by region
grouped_df<-as.data.frame(summarise_each(group_by(
select(combined_df, -Province.State), Country.Region), sum))
# compute risk and burden by region
grouped_df$risk<-grouped_df$deaths / grouped_df$recovered
grouped_df$burden<-grouped_df$confirmed * grouped_df$risk
confirmed_tb = kable(arrange(grouped_df, -confirmed)[1:5,])
deaths_tb = kable(arrange(grouped_df, -deaths)[1:5,])
recovered_tb = kable(arrange(grouped_df, -recovered)[1:5,])
cat("Top 5 confirmed regions ")
confirmed_tb
cat("Top 5 deaths regions ")
deaths_tb
cat("Top 5 recovered regions")
recovered_tb
save.image("C:/Users/wesne/OneDrive/Documents/RStudio/CSIT165/Project1/Project1.RData")
knitr::opts_chunk$set(echo = TRUE)
#### Load necessary packages ####
# * These packages are not necessary to complete the assignment and or only used
#   to provide an example.
packages <- c("knitr", "kableExtra", "magrittr", "readr", "geosphere", "dplyr")
install_me <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(install_me)) install.packages(install_me)
library(knitr)
library(kableExtra)
library(magrittr)
library(readr)
library(geosphere)
library(dplyr)
confirmed_df<-read.csv("data/time_series_covid19_confirmed_global.csv",
header=TRUE, stringsAsFactors=FALSE)
deaths_df<-read.csv("data/time_series_covid19_deaths_global.csv",
header=TRUE, stringsAsFactors=FALSE)
recovered_df<-read.csv("data/time_series_covid19_recovered_global.csv",
header=TRUE, stringsAsFactors=FALSE)
## Confirmed Dataset
confirmed_ordered<-select(arrange(confirmed_df, -X1.22.20),
Province.State, Country.Region, X1.22.20)
cat("Confirmed Dataset ")
head(confirmed_ordered)
## Deaths Dataset
death_ordered<-select(arrange(deaths_df, -X1.22.20),
Province.State, Country.Region, X1.22.20)
cat("Deaths Dataset ")
head(death_ordered)
## Recovered Dataset
recovered_ordered<-select(arrange(recovered_df, -X1.22.20),
Province.State, Country.Region, X1.22.20)
cat("Recovered Dataset \n")
head(recovered_ordered)
cat(confirmed_ordered[1,1], ", ", confirmed_ordered[1,2],
" has the most confirmed cases on the first day. \n",
death_ordered[1,1], ", ", death_ordered[1,2],
" has the most deaths from the virus on the first day. \n",
recovered_ordered[1,1], ", ", recovered_ordered[1,2],
" has the most recovered cases from the virus on the first day. \n",
sep="")
if (confirmed_ordered[1,1] == death_ordered[1,1] &&
confirmed_ordered[1,1] == recovered_ordered[1,1] &&
death_ordered[1,1] == recovered_ordered[1,1])
{
cat(confirmed_ordered[1,1], ", ", confirmed_ordered[1,2],
" is the most likely origin of the virus. \n", sep="")
}
confirmed_df<-read.csv("data/time_series_covid19_confirmed_global.csv",
header=TRUE, stringsAsFactors=FALSE)
recent_df<-arrange(confirmed_df[confirmed_df[,ncol(confirmed_df)-1] == 0
& confirmed_df[,ncol(confirmed_df)] > 0,])
i<-0
# If there are no new cases today loop back to find most recent region
# to have new cases
if (nrow(recent_df) == 0) {
while (nrow(recent_df) == 0) {
i<-i+1
recent_df<-arrange(confirmed_df[confirmed_df[,ncol(confirmed_df)-1-i] == 0
& confirmed_df[,ncol(confirmed_df)-i] > 0,])
}
}
head(select(recent_df, Province.State, Country.Region, ncol(confirmed_df)-1-i,
ncol(confirmed_df)-i))
# Vector is small enough that loop is reasonable
for(i in 1:nrow(recent_df))
{
if (recent_df[i,1] == "") {
cat(recent_df[i,2], "has recently had their first confirmed case. \n")
} else {
if (recent_df[i,2] == "") {
cat(recent_df[i,1], "has recently had their first confirmed case. \n")
} else {
cat(recent_df[i,1], ", ", recent_df[i,2],
" has recently had their first confirmed case. \n", sep="")
}
}
}
origin_df<-arrange(confirmed_df, -X1.22.20)[1,]
confirmed_df<-read.csv("data/time_series_covid19_confirmed_global.csv",
header=TRUE, stringsAsFactors=FALSE)
recent_df<-arrange(confirmed_df[confirmed_df[,ncol(confirmed_df)-1] == 0
& confirmed_df[,ncol(confirmed_df)] > 0,])
i<-0
# If there are no new cases today loop back to find most recent region
# to have new cases
if (nrow(recent_df) == 0) {
while (nrow(recent_df) == 0) {
i<-i+1
recent_df<-arrange(confirmed_df[confirmed_df[,ncol(confirmed_df)-1-i] == 0
& confirmed_df[,ncol(confirmed_df)-i] > 0,])
}
}
# Compute distances from origin
distances<-distm(select(recent_df, Long, Lat), select(origin_df, Long, Lat))
# Convert from m to miles
distances<-distances * 0.00062137
# Add distance from origin to dataframe and sort by distance
recent_df$distance<-distances[,1]
recent_df<-arrange(recent_df, distance)
head(select(recent_df, Province.State, Country.Region, Lat, Long, distance))
# Vector is small enough that loop is reasonable
for (i in 1:nrow(recent_df)) {
city<-recent_df[i, "Province.State"]
# If there is no city use country
if (city == "") {
city<-recent_df[i, "Country.Region"]
}
cat(city, "is", recent_df[i, "distance"],
"miles away from the virus origin in",
paste0(origin_df[1, "Province.State"], ","),
paste0(origin_df[1, "Country.Region"], "."), "\n")
}
# Datasets respresent a cumlative sum by date, so last column represents
# summation for region
confirmed_df<-read.csv("data/time_series_covid19_confirmed_global.csv",
header=TRUE, stringsAsFactors=FALSE)
confirmed_df<-select(confirmed_df, Province.State,
Country.Region, ncol(confirmed_df))
names(confirmed_df)[3] <- "confirmed"
deaths_df<-read.csv("data/time_series_covid19_deaths_global.csv",
header=TRUE, stringsAsFactors=FALSE)
deaths_df<-select(deaths_df, Province.State,
Country.Region, ncol(deaths_df))
names(deaths_df)[3] <- "deaths"
recovered_df<-read.csv("data/time_series_covid19_recovered_global.csv",
header=TRUE, stringsAsFactors=FALSE)
recovered_df<-select(recovered_df, Province.State,
Country.Region, ncol(recovered_df))
names(recovered_df)[3] <- "recovered"
# Combine the datasets into one and fill NA with 0
combined_df<-full_join(confirmed_df, recovered_df,
by=c("Province.State", "Country.Region"))
combined_df<-full_join(combined_df, deaths_df,
by=c("Province.State", "Country.Region"))
combined_df[is.na(combined_df)] <- 0
# Assignment is unclear if we are to consider state and region or
# just region. Based on how data is formatted, I think it is cleaner
# and makes more sence to use region only.  For instance, in confirmed
# dataset, Canada is broken up by region, but in recovered dataset it
# uses Canada as a whole.  There are numerous examples of this in
# the data
grouped_df<-as.data.frame(summarise_each(group_by(
select(combined_df, -Province.State), Country.Region), sum))
# Compute risk and burden by region
grouped_df$risk<-grouped_df$deaths / grouped_df$recovered
grouped_df$burden<-grouped_df$confirmed * grouped_df$risk
cat("Highest risk scores ")
head(arrange(grouped_df, -risk, -confirmed))
cat("Highest risk scores, that are not infinite ")
head(arrange(grouped_df[grouped_df$risk != Inf,], -risk, -confirmed))
cat("Lowest Risk Scores ")
head(arrange(grouped_df, risk, confirmed))
cat("Lowest risk scores, that are not zero ")
head(arrange(grouped_df[grouped_df$risk != 0,], risk, confirmed))
global_confirmed<-sum(grouped_df$confirmed)
global_deaths<-sum(grouped_df$deaths)
global_recovered<-sum(grouped_df$recovered)
global_risk<-global_deaths / global_recovered
global_burden<-global_confirmed * global_risk
cat("Global Data\n",
"Confirmed:", global_confirmed, "\n",
"Deaths:   ", global_deaths, "\n",
"Recovered:", global_recovered, "\n",
"Risk:     ", global_risk, "\n",
"Burden:   ", global_burden, "\n")
# Datasets respresent a cumlative sum by date, so last column represents
# sumation for region
confirmed_df<-read.csv("data/time_series_covid19_confirmed_global.csv",
header=TRUE, stringsAsFactors=FALSE)
confirmed_df<-select(confirmed_df, Province.State,
Country.Region, ncol(confirmed_df))
names(confirmed_df)[3] <- "confirmed"
deaths_df<-read.csv("data/time_series_covid19_deaths_global.csv",
header=TRUE, stringsAsFactors=FALSE)
deaths_df<-select(deaths_df, Province.State,
Country.Region, ncol(deaths_df))
names(deaths_df)[3] <- "deaths"
recovered_df<-read.csv("data/time_series_covid19_recovered_global.csv",
header=TRUE, stringsAsFactors=FALSE)
recovered_df<-select(recovered_df, Province.State,
Country.Region, ncol(recovered_df))
names(recovered_df)[3] <- "recovered"
# Combine the datasets into one and fill NA with 0
combined_df<-full_join(confirmed_df, recovered_df,
by=c("Province.State", "Country.Region"))
combined_df<-full_join(combined_df, deaths_df,
by=c("Province.State", "Country.Region"))
combined_df[is.na(combined_df)] <- 0
# Group and combine data by region
grouped_df<-as.data.frame(summarise_each(group_by(
select(combined_df, -Province.State), Country.Region), sum))
# Compute risk and burden by region
grouped_df$risk<-grouped_df$deaths / grouped_df$recovered
grouped_df$burden<-grouped_df$confirmed * grouped_df$risk
confirmed_tb = kable(arrange(grouped_df, -confirmed)[1:5,])
deaths_tb = kable(arrange(grouped_df, -deaths)[1:5,])
recovered_tb = kable(arrange(grouped_df, -recovered)[1:5,])
cat("Top 5 confirmed regions ")
confirmed_tb
cat("Top 5 deaths regions ")
deaths_tb
cat("Top 5 recovered regions")
recovered_tb
savehistory("C:/Users/wesne/OneDrive/Documents/RStudio/CSIT165/Project1/Project1.Rhistory")
